# DTW语音识别系统

基于动态时间规整（DTW）算法的数字语音识别系统 - 实验三

## 项目结构

```
exp3/
├── templates/                # 模板库（运行build_templates.py后生成）
│   ├── 0/                   # 数字0的模板
│   ├── 1/                   # 数字1的模板
│   └── ...                  # 数字2-9的模板
│
├── results/                 # 识别结果（运行run_recognition.py后生成）
│   └── visualizations/      # DTW对齐可视化图
│
├── src/                     # 源代码模块
│   ├── __init__.py         # 包初始化
│   ├── config.py           # 配置文件
│   ├── data_utils.py       # 数据处理
│   ├── features.py         # MFCC特征提取
│   ├── dtw_core.py         # DTW算法核心
│   └── visualization.py    # 可视化工具
│
├── build_templates.py       # 模板构建脚本（训练）
├── run_recognition.py       # 识别运行脚本（测试）
├── requirements.txt         # Python依赖包
└── README.md               # 本文件
```

## 功能说明

### 1. 配置文件 (`src/config.py`)
- 定义数据路径、数字列表、训练文件数量
- 配置MFCC参数（n_mfcc=13, 预加重系数=0.97等）

### 2. 数据处理 (`src/data_utils.py`)
- `get_audio_files()`: 扫描并过滤数字音频文件（只保留0-9）
- `split_train_test()`: 分割训练集（前4个）和测试集（第5个）
- `load_templates()`: 加载已保存的模板库

### 3. 特征提取 (`src/features.py`)
- `extract_mfcc()`: 从音频文件提取MFCC特征
  - 应用预加重处理
  - 提取13维MFCC系数

### 4. DTW算法 (`src/dtw_core.py`)
- `calculate_dtw_distance()`: 计算两个MFCC序列的DTW距离
  - 使用欧式距离
  - 返回累计最小距离

### 5. 可视化 (`src/visualization.py`)
- `plot_dtw_alignment()`: 绘制DTW对齐路径图
- `plot_dtw_cost_matrix()`: 绘制DTW代价矩阵

## 使用方法

### 环境准备

1. 安装Python依赖包：
```bash
pip install -r requirements.txt
```

### 运行流程

#### 步骤1: 构建模板库（训练阶段）

```bash
cd exp3
python build_templates.py
```

该脚本会：
- 扫描 `../dataset/VAD/` 目录下的音频文件
- 过滤出数字0-9的音频（忽略汉字音频）
- 提取前4个音频的MFCC特征
- 保存到 `templates/` 目录

输出示例：
```
============================================================
DTW语音识别系统 - 模板构建
============================================================

[步骤 1/3] 扫描音频文件...
找到 50 个数字音频文件
  数字 0: 5 个文件
  数字 1: 5 个文件
  ...

[步骤 2/3] 分割数据集...
训练集: 40 个文件 (每个数字 4 个)
测试集: 10 个文件 (每个数字 1 个)

[步骤 3/3] 提取MFCC特征并构建模板库...
  [ 1/40] 数字 0: 0_1_xiugai2.wav -> MFCC形状: (13, 94)
  [ 2/40] 数字 0: 0_2_xiugai2.wav -> MFCC形状: (13, 87)
  ...

============================================================
✓ 模板构建完成！共创建 40 个模板
✓ 模板保存在: templates/
============================================================
```

#### 步骤2: 运行识别（测试阶段）

```bash
python run_recognition.py
```

该脚本会：
- 加载模板库
- 对第5个音频进行识别
- 使用DTW算法匹配最相似的模板
- 生成识别结果和统计报告
- （可选）生成前几个样本的DTW对齐可视化图

输出示例：
```
============================================================
DTW语音识别系统 - 语音识别
============================================================

[步骤 1/4] 加载模板库...
成功加载 40 个模板
  数字 0: 4 个模板
  数字 1: 4 个模板
  ...

[步骤 2/4] 获取测试文件...
找到 10 个测试文件

[步骤 3/4] 开始识别...
------------------------------------------------------------
✓ [ 1] 文件: 0_5_xiugai2.wav        | 真实: 0 | 预测: 0 | 距离: 245.32
✓ [ 2] 文件: 1_5_xiugai2.wav        | 真实: 1 | 预测: 1 | 距离: 312.45
...

[步骤 4/4] 识别结果统计
============================================================

总体识别结果:
  测试样本数: 10
  识别正确数: 9
  识别错误数: 1
  识别准确率: 90.00%

各数字识别准确率:
  数字 0: 1/1 (100.00%)
  数字 1: 1/1 (100.00%)
  ...

混淆矩阵 (行:真实, 列:预测):
        0   1   2   3   4   5   6   7   8   9
  0 |   1   0   0   0   0   0   0   0   0   0
  1 |   0   1   0   0   0   0   0   0   0   0
  ...

============================================================
✓ 识别完成！最终准确率: 90.00%
✓ 对齐可视化图已保存到: results/visualizations/
============================================================
```

## 技术细节

### MFCC参数
- **倒谱系数数量**: 13
- **FFT窗口**: 2048
- **帧移**: 512
- **预加重系数**: 0.97

### DTW算法
- **距离度量**: 欧式距离
- **对齐方式**: 动态时间规整
- **匹配策略**: 与所有模板计算距离，选择最小距离对应的数字

### 数据说明
- **数据来源**: `../dataset/VAD/` （VAD处理后的音频）
- **识别对象**: 仅识别数字0-9
- **文件命名**: `数字_序号_xiugai2.wav` （如 `0_1_xiugai2.wav`）
- **训练/测试分割**: 前4个用于训练，第5个用于测试

## 注意事项

1. 确保数据集已经过VAD处理并存放在 `../dataset/VAD/` 目录
2. 文件命名格式必须为 `数字_序号_*.wav`
3. 每个数字至少需要5个音频文件
4. 必须先运行 `build_templates.py` 再运行 `run_recognition.py`
5. 汉字音频文件（如 `cheng_1_xiugai2.wav`）会被自动过滤

## 依赖包

- numpy: 数值计算
- librosa: 音频处理和MFCC提取
- dtw-python: DTW算法实现
- matplotlib: 可视化绘图

## 实验报告

本系统实现了完整的DTW语音识别流程：
1. **特征提取**: 使用MFCC表征音频信号
2. **模板匹配**: 通过DTW算法处理时长差异
3. **识别决策**: 选择最小DTW距离对应的数字
4. **性能评估**: 输出准确率和混淆矩阵

适用于实验三的所有要求。

